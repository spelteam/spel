#! /usr/bin/env python2.7

import glob
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import argparse
import numpy as np
import matplotlib.image as mpimg
from matplotlib.lines import Line2D
from pylab import figure, show
import math
import os
import re
import random

def usage():

	print("Author: Mykyta Fastovets / poselib project / 2015")
	print("This utility is an analysis tool for plotting error files generated by the poselib tuners.")
	print("Input should be a .err file.")
	print("Example usage: ./plotSimVsTemp.py ~/file.err ")

def dist(a,b):

	return math.sqrt((a[0]-b[0])**2+(a[1] - b[1])**2)

parser = argparse.ArgumentParser(description='1 non-optional argument')

parser.add_argument('ERRIN', action="store")
parseResult = parser.parse_args()

#DATADIR contains that folder that contains all other data
errFile = parseResult.ERRIN

plotTitle = errFile.split('_')[-1].split('.')[0]

print 'Reading '+errFile

myFile = open(errFile) 
data = [line.strip().split() for line in open(errFile)] #read the data from the int file

frameIndex=-1
partIndex=-1
paramValue=-1

itemIndex=0
readMode = 'false'
result=[]

	
paramData=[]
frameData=[]
partData=[]

for dataItem in data:


	if dataItem[0]=='{':
		readMode='true'
		paramValue=data[itemIndex-1][0]

	elif dataItem[0]=='}':
		result.append([paramValue, paramData])
		paramData=[]

	elif dataItem[0]=='[':
		frameIndex=data[itemIndex-1][0]

	elif dataItem[0]==']':
		paramData.append([frameIndex, frameData])
		frameData=[]

	elif dataItem[0]=='(':
		partIndex=data[itemIndex-1][0]

	elif dataItem[0]==')':
		frameData.append([partIndex, partData])
		partData=[]

	elif len(dataItem)>1 and readMode=='true':
		#print dataItem
		#raw_input('test')
		partData.append(dataItem)
		# print 'ITEM '+ str(dataItem[0])
		# print dataItem
		# print 'PART '+str(partIndex)
		# print partData
		# print 'FRAME '+str(frameIndex)
		# print frameData
		# print 'PARAM '+str(paramValue)
		# print paramData
		# print 'RESULT '
		# print result
		#raw_input('test')
		
	itemIndex+=1

#Create plottable objects, with in x,y format and define the graphs that will be produced

numParams = len(result)

#Detector quality graphs, to measure correspondence of score to RMS error, there will be a line for each param
numTopLables=100 #define number of labels from the top scorers to take
percentTopLabels=10 #define the percentage of labels to analyse more deeply from the top

topErrorsP = [] #percent errors
topErrorsA = [] #absolute errors

#Param evaluation graphs, to measure how each parameter setting performs
percentileParamErrors=[]

#print result
nParts = 0


tme=[] #top scoring #1 ranked label ERROR, for each param, we want this to be low
tms=[] #top scoring #1 ranked label SCORE, for each param, we want this to be low

tmi=[] #lowest error label index within percentTopLabels, for each param, we want this to be low
tmig=[] #lowest error label index GLOBALLY, for each param, we want this to be low
tmigp=[]

nal=[] #number of acceptable labels within percentTopLabels, we want this to be high, accept thresh defined in detectorTuner


for i in range(numParams):

	tme.append([])
	tmi.append([])
	tms.append([])
	tmig.append([])
	nal.append([])
	tmigp.append([])


	topErr=[]
	topCnt=[]

	topErrAbs=[]
	topCntAbs=[]

	for r in range(numTopLables):
		topErr.append(0)
		topCnt.append(0)
		topErrAbs.append(0)
		topCntAbs.append(0)
		
	pcol = "#%06x" % random.randint(0,0xFFFFFF)
	numFrames = len(result[i][1])

	x = []
	y = []
	z = []
	z2 = []
	r10=[]

	rTest=0
	rCount=0

	R=[]
	for r in range(11):
		R.append(0)

	partErrors=[] #errors 
	for j in range(numFrames):

		partFrameErrors=[]

		numParts = len(result[i][1][j][1])

		nParts=numParts

		avgMinIndex=0.0
		rmsError=0.0
		RMS=[]

		for r in range(11):
			RMS.append(0)

		#print i
		#print j
		#print numParts

		for k in range(numParts):

			partID = result[i][1][j][1][k][0]
			
			numLabels=len(result[i][1][j][1][k][1]) #number of labels in this part

			if partID > 5 or partID == 0: #discard limbs 1 through 5

				tenth=float(numLabels)*0.1
				percent = float(numLabels)*0.01

				col = "#%06x" % random.randint(0,0xFFFFFF)
				minError=1000000000
				minIndex=-1.0

				topScoreVal = float(result[i][1][j][1][k][1][0][1])

				topMinErr=1000000000
				topMinIndex=-1.0

				rms=[]
				cnts=[]
				
				for r in range(11):
					rms.append(0)
					cnts.append(0)


				topError=float(result[i][1][j][1][k][1][0][2])
				topErrors=[] #are the any other top errors with same support score?

				rms[0] = topError #set the top error
				cnts[0]=1

				acceptCount=0


				for l in range(numLabels):
					
					errVal = float(result[i][1][j][1][k][1][l][2]) #finalScore (support)
					scoreVal = float(result[i][1][j][1][k][1][l][1]) #partError[e] (err to GT)
					acceptVal = float(result[i][1][j][1][k][1][l][3]) #isAccepted (is this close enough?)

					if errVal <= topError:
						topErrors.append(errVal)

					if l<numTopLables:
						topErrAbs[l]+=errVal
						topCntAbs[l]+=1

					index=int(l/percent)
					
				#if errVal!=0: #don't count invalid error values (zero is practically impossible, treat as a bug)

					topErr[index]+=errVal
					topCnt[index]+=1

					if l<tenth:

						rms[1]+=errVal #add error
						cnts[1]+=1
						rTest+=errVal
						rCount+=1
						if errVal < topMinErr:
							topMinErr = errVal
							topMinIndex = l

						if errVal<10:
							acceptCount+=1


					if l<tenth*2:
						rms[2]+=errVal #add error
						cnts[2]+=1
					if l<tenth*3:
						rms[3]+=errVal #add error
						cnts[3]+=1
					if l<tenth*4:
						rms[4]+=errVal #add error
						cnts[4]+=1
					if l<tenth*5:
						rms[5]+=errVal #add error
						cnts[5]+=1
					if l<tenth*6:
						rms[6]+=errVal #add error
						cnts[6]+=1
					if l<tenth*7:
						rms[7]+=errVal #add error
						cnts[7]+=1
					if l<tenth*8:
						rms[8]+=errVal #add error
						cnts[8]+=1
					if l<tenth*9:
						rms[9]+=errVal #add error
						cnts[9]+=1
					if l<tenth*10:
						rms[10]+=errVal #add error
						cnts[10]+=1
		
					if float(result[i][1][j][1][k][1][l][2]) < minError:
						minError = errVal
						minIndex = int(result[i][1][j][1][k][1][l][0])

				for ev in range(11):
					if ev>0 and tenth>0:
						RMS[ev]+=float(rms[ev])/float(cnts[ev])

				rmsError+=topError
				avgMinIndex+=minIndex

				tme[i].append(topError) #take the top labels's error
				for erv in topErrors:
					tme[i].append(erv)

				tmi[i].append(topMinIndex) #store the index of the lowest label within 10%
				tms[i].append(topScoreVal)
				tmig[i].append(minIndex)
				tmigp[i].append(float(minIndex)/float(numLabels)*100.0)
				nal[i].append(acceptCount)

				partFrameErrors.append(partErrors)
		
		for ev in range(11):
			if ev>0 and numParts>0:
				R[ev] += float(RMS[ev])/float(numParts)
		
		avgMinIndex=float(avgMinIndex)/float(numParts)
		rmsError=float(rmsError)/float(numParts)

		x.append(float(result[i][0])) #
		y.append(int(result[i][1][j][0])) #frame number
		z.append(avgMinIndex) #average index
		z2.append(rmsError) #rms error for all top labels

	for r in range(numTopLables):
		if topCnt[r]!=0:
			topErr[r]=topErr[r]/topCnt[r]
		if topCntAbs[r]!=0:
			topErrAbs[r] = topErrAbs[r]/topCntAbs[r]

	for ev in range(11):
		if ev>0 and numParts>0:
			R[ev] = float(R[ev])/float(numFrames)

	#partParamErrors.append(partErrors)
	topErrorsP.append(topErr)
	topErrorsA.append(topErrAbs)
	percentileParamErrors.append(R)

#Now do the parts analysis for top 10% of labels
partParamErrors=[] #not done yet

for i in range(numParams):

	numFrames = len(result[i][1])

	partErrors=[]


	for r in range(nParts):
		partErrors.append(0)

	for j in range(numFrames):

		numParts = len(result[i][1][j][1])

		for k in range(numParts):

			partErr=0
			partCnt=0

			partID = int(result[i][1][j][1][k][0])
			
			numLabels=len(result[i][1][j][1][k][1]) #number of labels in this part

			tenth=float(numLabels)*0.1

			for l in range(numLabels):
				errVal = float(result[i][1][j][1][k][1][l][2])
				if l<tenth:
					partErr+=errVal #add error
					partCnt+=1

			#print float(partErr)/float(partCnt)
			partErrors[partID]+=float(partErr)/float(partCnt) #store averages across labels

	for p in range(len(partErrors)):
		partErrors[p] = float(partErrors[p])/float(numFrames) #divide by numFrames
		#print partErrors[p]
		#raw_input('not here')

	partParamErrors.append(partErrors)

#print partParamErrors
#raw_input('here')

figSize=(16, 9)
figSize2=(19.20, 10.80)
#Do plotting
fig1 = plt.figure(1, figsize=figSize, dpi=600)
fig2 = plt.figure(2, figsize=figSize, dpi=600)
fig3 = plt.figure(3, figsize=figSize, dpi=600)
fig4 = plt.figure(4, figsize=figSize, dpi=600)
fig5 = plt.figure(5, figsize=figSize, dpi=600)
fig6 = plt.figure(6, figsize=figSize, dpi=600)

ax1 = fig1.add_subplot(111)#, projection='2d')
ax1.yaxis.grid(True, linestyle='-', which='major', color='lightgrey',
              alpha=0.5)
ax1.xaxis.grid(True, linestyle='-', which='major', color='lightgrey',
              alpha=0.5)

ax2 = fig2.add_subplot(111)#, projection='2d')
ax2.yaxis.grid(True, linestyle='-', which='major', color='lightgrey',
              alpha=0.5)
ax2.xaxis.grid(True, linestyle='-', which='major', color='lightgrey',
              alpha=0.5)

ax3 = fig3.add_subplot(111)#, projection='3d')
ax3.yaxis.grid(True, linestyle='-', which='major', color='lightgrey',
              alpha=0.5)
ax3.xaxis.grid(True, linestyle='-', which='major', color='lightgrey',
              alpha=0.5)

ax4 = fig4.add_subplot(111)#, projection='3d')
ax4.yaxis.grid(True, linestyle='-', which='major', color='lightgrey',
              alpha=0.5)
ax4.xaxis.grid(True, linestyle='-', which='major', color='lightgrey',
              alpha=0.5)

ax5 = fig5.add_subplot(111)#, projection='3d')
ax5.yaxis.grid(True, linestyle='-', which='major', color='lightgrey',
              alpha=0.5)
ax5.xaxis.grid(True, linestyle='-', which='major', color='lightgrey',
              alpha=0.5)

ax6 = fig6.add_subplot(111)#, projection='3d')
ax6.yaxis.grid(True, linestyle='-', which='major', color='lightgrey',
              alpha=0.5)
ax6.xaxis.grid(True, linestyle='-', which='major', color='lightgrey',
              alpha=0.5)

# dx = fig2.add_subplot(212)#, projection='3d')
# dx.yaxis.grid(True, linestyle='-', which='major', color='lightgrey',
#               alpha=0.5)
# dx.xaxis.grid(True, linestyle='-', which='major', color='lightgrey',
#               alpha=0.5)


pcol = [(0.94,0.64,1.0),(0.0,0.46,0.86),(0.6,0.25,0.0),(0.3,0,0.36),(0.1,0.1,0.1),(0,0.36,0.19),(0.17,0.8,0.28),(1,0.8,0.6),
(0.5,0.5,0.5),(0.58,1,0.71),(0.56,0.47,0), (0.6, 0.8, 1.0), (0.25, 0.6, 0.0), (0.86, 0.0, 0.46), (1.0, 1.0, 0.64), (0, 0.5, 1.0), (1.0, 0.5, 0.0)]

#colors = itertools.cycle(['red', 'blue', 'green', 'magenta', 'cyan', 'black'])

paramName = data[4][1]
paramVals=[]
pp=[]
pc=[]

for p in range(nParts):
	pc.append([])

for p in range(nParts):
	for i in range(numParams):
		pc[p].append(partParamErrors[i][p]) #this is the part error at this param value
		#print partParamErrors[i][p]

#print percentileParamErrors

for i in range(numParams):

	paramVal = result[i][0]
	paramVals.append(paramVal)
	pp.append(percentileParamErrors[i][1])

	
	ax6.plot(range(numTopLables), topErrorsP[i], color=pcol[i], alpha=1.0, label=str(result[i][0]), linewidth=4.0) #label rank (%) vs error to GT
	#dx.plot(range(numTopLables), topErrorsA[i], color=pcol[i], alpha=1.0, label=str(result[i][0]), linewidth=4.0) #draw min ranks



# for p in range(nParts):

# 	if p==0 or p>5: #=0 or p>5: # don't plot the useless parts
# 		bx.plot(paramVals, pc[p], color=pcol[p], alpha=1.0, label='Part '+str(p), linewidth=4.0)#, label=str(ev)) #a point at each parameters setting, where ev is the percentile 0=1, 1=10,..., 10=100

#bx.plot(paramVals, pp, color='red', alpha=1.0, label='Average', linewidth=6.0)#, label=str(ev)) #a point at each parameters setting, where ev is the percentile 0=1, 1=10,..., 10=100

fontSizeLabels=30
fontSizeTitle=45
fontSizeTicks=25

boxprops = dict(linestyle='-', linewidth=4, color='blue')
flierprops = dict(marker='-', markerfacecolor='green', markersize=315, linestyle='-', linewidth=4)
medianprops = dict(linestyle='-', linewidth=4, color='firebrick')
meanpointprops = dict(marker='D', markeredgecolor='black', markerfacecolor='firebrick', markersize=15)
#meanlineprops = dict(linestyle='--', linewidth=2.5, color='purple')

#print tmi

plt.tick_params(axis='both', which='major', labelsize=fontSizeTicks)
plt.tick_params(axis='both', which='minor', labelsize=fontSizeTicks)

ax1.boxplot(tmi, boxprops=boxprops, meanprops=meanpointprops, medianprops=medianprops, meanline=False, showmeans=True, whis='range') #within top 10%, min index
ax1.set_xlabel(paramName+' value', fontsize=fontSizeLabels)
ax1.set_ylabel('Min. error detection rank', fontsize=fontSizeLabels)
ax1.set_xticklabels(paramVals, fontsize=fontSizeTicks)
ax1.tick_params(axis='both', which='major', labelsize=fontSizeTicks)
ax1.tick_params(axis='both', which='minor', labelsize=fontSizeTicks)

ax2.boxplot(tme, boxprops=boxprops) #number one label error
ax2.set_xlabel(paramName+' value', fontsize=fontSizeLabels)
ax2.set_ylabel('Detection RMS error (pix)', fontsize=fontSizeLabels)
#plt.tick_params(axis='both', which='major', labelsize=fontSizeTicks)
#plt.tick_params(axis='both', which='minor', labelsize=fontSizeTicks)
ax2.tick_params(axis='both', which='major', labelsize=fontSizeTicks)
ax2.tick_params(axis='both', which='minor', labelsize=fontSizeTicks)

ax3.boxplot(tmigp, boxprops=boxprops, meanprops=meanpointprops, medianprops=medianprops, meanline=False, showmeans=True, whis='range') #globally, min index
ax3.set_xlabel(paramName+' value', fontsize=fontSizeLabels)
ax3.set_ylabel('Min. error detection rank', fontsize=fontSizeLabels)
#plt3.tick_params(axis='both', which='major', labelsize=fontSizeTicks)
#plt3.tick_params(axis='both', which='minor', labelsize=fontSizeTicks)
ax3.set_xticklabels(paramVals, fontsize=fontSizeTicks)
ax3.tick_params(axis='both', which='major', labelsize=fontSizeTicks)
ax3.tick_params(axis='both', which='minor', labelsize=fontSizeTicks)

ax4.boxplot(tms, boxprops=boxprops, meanprops=meanpointprops, medianprops=medianprops, meanline=False, showmeans=True, whis='range') #number one label scores
ax4.set_xlabel(paramName+' value', fontsize=fontSizeLabels)
ax4.set_ylabel('Detection score', fontsize=fontSizeLabels)
#plt4.tick_params(axis='both', which='major', labelsize=fontSizeTicks)
#plt4.tick_params(axis='both', which='minor', labelsize=fontSizeTicks)
ax4.set_xticklabels(paramVals, fontsize=fontSizeTicks)
ax4.tick_params(axis='both', which='major', labelsize=fontSizeTicks)
ax4.tick_params(axis='both', which='minor', labelsize=fontSizeTicks)

ax5.boxplot(nal, boxprops=boxprops, meanprops=meanpointprops, medianprops=medianprops, meanline=False, showmeans=True, whis='range') #number of acceptable detections within .25 of box width
ax5.set_xlabel(paramName+' value', fontsize=fontSizeLabels)
ax5.set_ylabel('Acceptable detections', fontsize=fontSizeLabels)
#plt5.tick_params(axis='both', which='major', labelsize=fontSizeTicks)
#plt5.tick_params(axis='both', which='minor', labelsize=fontSizeTicks)
ax5.set_xticklabels(paramVals, fontsize=fontSizeTicks)
ax5.tick_params(axis='both', which='major', labelsize=fontSizeTicks)
ax5.tick_params(axis='both', which='minor', labelsize=fontSizeTicks)

#already plotted
ax6.set_xlabel('Label rank (%)', fontsize=fontSizeLabels)
ax6.set_ylabel('RMS error (pix)', fontsize=fontSizeLabels)
#plt6.tick_params(axis='both', which='major', labelsize=fontSizeTicks)
#plt6.tick_params(axis='both', which='minor', labelsize=fontSizeTicks)
#ax6.set_xticklabels(paramVals)

handles1, labels1 = ax6.get_legend_handles_labels()
ax6.legend(handles1, labels1)
ax6.grid()
ax6.legend(loc='upper left', bbox_to_anchor=(0.0, 1.00),
         ncol=3, fancybox=True, shadow=True, prop={'size':20})
ax6.get_legend().set_title(title=paramName+" value", prop={'size':20})

# params = {'legend.fontsize': 25,
#           'legend.handlelength': 2}
# plt.rcParams.update(params)
# plt.rc('legend',**{'fontsize':30})

# plt.tick_params(axis='both', which='major', labelsize=20)
# plt.tick_params(axis='both', which='minor', labelsize=20)

# bx.set_xlabel(paramName+' value', fontsize=25)
# bx.set_ylabel('Detection RMS Error (pixels)', fontsize=25)

# cx.set_xlabel('Label Rank (%)', fontsize=25)
# cx.set_ylabel('RMS Error (pixels)', fontsize=25)

# # dx.set_xlabel('Label Rank', fontsize=18)
# # dx.set_ylabel('RMS Error (pixels)', fontsize=18)

# handles1, labels1 = bx.get_legend_handles_labels()
# bx.legend(handles1, labels1)
# bx.grid()
# bx.legend(loc='upper center', bbox_to_anchor=(0.5, 1.05),
#           ncol=3, fancybox=True, shadow=True)
# bx.get_legend().set_title(title="Part")

# handles, labels = cx.get_legend_handles_labels()
# cx.legend(handles, labels)
# cx.grid()
# cx.legend(loc='upper center', bbox_to_anchor=(0.5, 1.05),
#           ncol=3, fancybox=True, shadow=True)
# cx.get_legend().set_title(title=str(paramName)+" value")

# plt.setp(cx.get_legend().get_title(),fontsize=24)
# plt.setp(bx.get_legend().get_title(),fontsize=24)

print errFile.split('.')

plotTitle = errFile.split('_')[-1].split('.')[0]
plotSave = '..'+errFile.split('.')[2]

#plotSave = errFile.split('.')[0]+'_s.png'
#plot2Save = errFile.split('.')[0]+'_q.png'

fig1.suptitle("Min Index in Top 10%", fontsize=fontSizeTitle)
fig2.suptitle("Top Scoring Detection Error", fontsize=fontSizeTitle)
fig3.suptitle("Global Min Index", fontsize=fontSizeTitle)
fig4.suptitle("Top Scoring Detection Score", fontsize=fontSizeTitle)
fig5.suptitle("Acceptable Detections in Top 10%", fontsize=fontSizeTitle)
fig6.suptitle("Error vs Label Rank", fontsize=fontSizeTitle)


fig1.savefig(plotSave+'_tmi.png', bbox_inches='tight')
fig2.savefig(plotSave+'_tme.png', bbox_inches='tight')
fig3.savefig(plotSave+'_tmig.png', bbox_inches='tight')
fig4.savefig(plotSave+'_tms.png', bbox_inches='tight')
fig5.savefig(plotSave+'_tme.png', bbox_inches='tight')
fig6.savefig(plotSave+'_re.png', bbox_inches='tight')


print 'Saved to '+ plotSave